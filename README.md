# Microsoft sentence completion challenge

The Microsoft Research Sentence Completion Challenge (Zweig and Burges, 2011) requires a system to be able to predict which is the most likely word (from a set of 5 possibilities) to complete a sentence.

## Data

The training data used is the Holmes Training Data, which includes approximately more than 500 novels.

The testing data is the data generated by Microsoft for this challenge.

## Approach
In this repo, I demonstrate 2 types of approaches: classical & deep learning based. For more details on how the approaches are developed, refer to `doc/submission.docx`

### Classical 
In classical approach, unigram and bigram are used to calculate the probability of each option and the most likely one are chosen. There are also several techniques that are adopted in this approach:
- Unknown words
- Smoothing (Absolute vs. Kneser Ney)
- Probability backing off

### Deep learning
In deep learning approach, two methods are tested, one is to use pretrained model from Huggingface.co as is to get the result. Another is to use BiLSTM and train that model on the Holmes training dataset specified above.

#### Pretrained model
In this project, BERT (base/large, uncased/cased) and RoBERTA (base/large) are tested. To determine the answer, 4 approaches are used:
- Get the probability of the first token of each answer and choose the highest
- Get the embeddings of each token of each answer, perform pooling and choose the answers that are the most similar to the most probable answer predicted by the model.
  - Mean pooling
  - Max pooling
  - Min pooling 

#### BiLSTM
In this approach, the training data is first processed using one of the 3 NLP packages (NLTK, Spacy, Stanza). Each document is first divided into sentences, and each of these sentences if applied a random mask to obtain the training dataset for the model. The negative options for each sentence is randomly chosen from the vocabulary.

The masked sentences are tokenized, and then fed into an embedding model, which is either Word2Vec, Glove or FastText. Embedded tokens are then put through BiLSTM model to obtain the forward and backward hidden states at the masked location. Then, the hidden states are then concatenated and fed into a fully connected layers so that the output has the same size as the embeddings. Lastly, the similarity between each answer and the outputs are then calculated and most similar answer are chosen. 

Objective loss used in this approach is triplet loss. At each training stage, the correct answer and one of the 4 false answers are randomly chosen.

To check the performance of the BiLSTM model on this task, run the following code in the command line:
```
tensorboard --logdir=tensorboard
```

