{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n"
          ]
        }
      ],
      "source": [
        "import os,random,math,sys\r\n",
        "import multiprocessing\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\r\n",
        "from tqdm import tqdm\r\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "\r\n",
        "parentdir='data/raw_data'\r\n",
        "TRAINING_DIR=parentdir+'/Holmes_Training_Data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9r6277Rv6_Im"
      },
      "outputs": [],
      "source": [
        "test_data=pd.read_csv(os.path.join(parentdir,'testing_data.csv'),index_col=0)\n",
        "test_answer=pd.read_csv(os.path.join(parentdir,'test_answer.csv'),index_col=0).iloc[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "RVZdJ90Y9yER",
        "outputId": "5a3b58f5-3784-4d26-f307-6eda41aea17a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>a)</th>\n",
              "      <th>b)</th>\n",
              "      <th>c)</th>\n",
              "      <th>d)</th>\n",
              "      <th>e)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have it from the same source that you are bo...</td>\n",
              "      <td>crying</td>\n",
              "      <td>instantaneously</td>\n",
              "      <td>residing</td>\n",
              "      <td>matched</td>\n",
              "      <td>walking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It was furnished partly as a sitting and partl...</td>\n",
              "      <td>daintily</td>\n",
              "      <td>privately</td>\n",
              "      <td>inadvertently</td>\n",
              "      <td>miserably</td>\n",
              "      <td>comfortably</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As I descended , my old ally , the _____ , cam...</td>\n",
              "      <td>gods</td>\n",
              "      <td>moon</td>\n",
              "      <td>panther</td>\n",
              "      <td>guard</td>\n",
              "      <td>country-dance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We got off , _____ our fare , and the trap rat...</td>\n",
              "      <td>rubbing</td>\n",
              "      <td>doubling</td>\n",
              "      <td>paid</td>\n",
              "      <td>naming</td>\n",
              "      <td>carrying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>He held in his hand a _____ of blue paper , sc...</td>\n",
              "      <td>supply</td>\n",
              "      <td>parcel</td>\n",
              "      <td>sign</td>\n",
              "      <td>sheet</td>\n",
              "      <td>chorus</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question        a)  \\\n",
              "id                                                                \n",
              "1   I have it from the same source that you are bo...    crying   \n",
              "2   It was furnished partly as a sitting and partl...  daintily   \n",
              "3   As I descended , my old ally , the _____ , cam...      gods   \n",
              "4   We got off , _____ our fare , and the trap rat...   rubbing   \n",
              "5   He held in his hand a _____ of blue paper , sc...    supply   \n",
              "\n",
              "                 b)             c)         d)             e)  \n",
              "id                                                            \n",
              "1   instantaneously       residing    matched        walking  \n",
              "2         privately  inadvertently  miserably    comfortably  \n",
              "3              moon        panther      guard  country-dance  \n",
              "4          doubling           paid     naming       carrying  \n",
              "5            parcel           sign      sheet         chorus  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrrRUMlCuAtv"
      },
      "source": [
        "# Pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4ypaJGz5t-fN"
      },
      "outputs": [],
      "source": [
        "answers={\r\n",
        "    0:'a',\r\n",
        "    1:'b',\r\n",
        "    2:'c',\r\n",
        "    3:'d',\r\n",
        "    4:'e'\r\n",
        "}\r\n",
        "\r\n",
        "def get_options_indices(tokenizer,prefix,options):\r\n",
        "    \"\"\"\r\n",
        "    Converting options' text into id of the tokenizer\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    - tokenizer: PretrainedTokenizer\r\n",
        "    - options: list\r\n",
        "\r\n",
        "    Return: indices of each option's text (list)\r\n",
        "    \"\"\"\r\n",
        "    indices=[tokenizer(option)['input_ids'][1:-1] for option in options]\r\n",
        "    for i,option in enumerate(options):\r\n",
        "        if prefix+option in tokenizer.vocab.keys():\r\n",
        "            indices[i]=[tokenizer.convert_tokens_to_ids(prefix+option)]\r\n",
        "    return indices\r\n",
        "\r\n",
        "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\r\n",
        "\r\n",
        "class pretrained_model_tester():\r\n",
        "    def __init__(self,test_df,model_checkpoint):\r\n",
        "        self.tokenizer=AutoTokenizer.from_pretrained(model_checkpoint)\r\n",
        "        self.model=AutoModelForMaskedLM.from_pretrained(model_checkpoint).to(device)\r\n",
        "        self.model.eval()\r\n",
        "        self.test_data=test_df.copy()\r\n",
        "        if 'roberta' in model_checkpoint:\r\n",
        "            self.test_data.question=self.test_data.question.str.replace('_____','<mask>')\r\n",
        "            self.embedding_weight=self.model.roberta.embeddings.word_embeddings.weight\r\n",
        "            self.prefix='Ä '\r\n",
        "        else:\r\n",
        "            self.test_data.question=self.test_data.question.str.replace('_____','[MASK]')\r\n",
        "            self.embedding_weight=self.model.bert.embeddings.word_embeddings.weight\r\n",
        "            self.prefix=''\r\n",
        "\r\n",
        "    def predict(self,question,options,result_method,pooling_method):\r\n",
        "        \"\"\"\r\n",
        "        Perform sentence splitting, tokenizing, applying model and get result.\r\n",
        "\r\n",
        "        Arguments:\r\n",
        "        - question: string\r\n",
        "            text with masked token\r\n",
        "        - options: list of string\r\n",
        "            option to be chosen\r\n",
        "        - result_method: string\r\n",
        "            `base_only` (use only the first token of the option) or `all` (use every token)\r\n",
        "        - pooling_method: string\r\n",
        "            `sum` (summing all the embedding of tokens together) or `mean` (averaging all the embedding of tokens together)\r\n",
        "\r\n",
        "        Return: index of the option chosen (int)\r\n",
        "        \"\"\"\r\n",
        "        # tokenizing\r\n",
        "        inputs=self.tokenizer(question,return_tensors='pt')\r\n",
        "        # move to gpu if available\r\n",
        "        inputs={key: value.to(device) for key, value in inputs.items()}\r\n",
        "        # misc\r\n",
        "        masked_index=np.where((inputs['input_ids']==self.tokenizer.mask_token_id).cpu())[1][0]\r\n",
        "        options_indices=get_options_indices(self.tokenizer,self.prefix,options)\r\n",
        "        # get result\r\n",
        "        with torch.no_grad():\r\n",
        "            outputs=self.model(**inputs)[0]\r\n",
        "            if result_method=='base_only':\r\n",
        "                options_indices=[option[0] for option in options_indices]\r\n",
        "                outputs=outputs[:,masked_index,options_indices]\r\n",
        "                return torch.argmax(outputs).item()\r\n",
        "            elif result_method=='all':\r\n",
        "                predicted_index=torch.argmax(outputs[0, masked_index]).item()\r\n",
        "                predicted_embedding=self.embedding_weight[predicted_index,:]\r\n",
        "                similarity=[]\r\n",
        "                for indices in options_indices:\r\n",
        "                    if pooling_method=='mean':\r\n",
        "                        similarity.append(cos(predicted_embedding,self.embedding_weight[indices,:].mean(axis=0)).item())\r\n",
        "                    elif pooling_method=='max':\r\n",
        "                        similarity.append(cos(predicted_embedding,self.embedding_weight[indices,:].max(axis=0)[0]).item())\r\n",
        "                    elif pooling_method=='min':\r\n",
        "                        similarity.append(cos(predicted_embedding,self.embedding_weight[indices,:].min(axis=0)[0]).item())\r\n",
        "                    else:\r\n",
        "                        raise TypeError('pooling_method must be `mean`, `max` or `min` when result_method is `all`')\r\n",
        "                return np.argmax(similarity)\r\n",
        "            else:\r\n",
        "                raise TypeError('result_method must be either `base_only` or `all`')\r\n",
        "    \r\n",
        "    def batch_predict(self,result_method,pooling_method='sum'):\r\n",
        "        \"\"\"\r\n",
        "        Perform prediction on the whole test df\r\n",
        "\r\n",
        "        Arguments:\r\n",
        "        - result_method: string\r\n",
        "            `base_only` (use only the first token of the option) or `all` (use every token)\r\n",
        "        - pooling_method: string\r\n",
        "            `sum` (summing all the embedding of tokens together) or `mean` (averaging all the embedding of tokens together)\r\n",
        "\r\n",
        "        Return: answers of the questions (pandas series) \r\n",
        "        \"\"\"\r\n",
        "        result=[]\r\n",
        "        for index, row in self.test_data.iterrows():\r\n",
        "            question=row[0]\r\n",
        "            options=row[1:].tolist()\r\n",
        "            predicted_ind=self.predict(question,options,result_method,pooling_method)\r\n",
        "            result.append(answers[predicted_ind])\r\n",
        "        return pd.Series(result,index=test_data.index)\r\n",
        "\r\n",
        "def get_accuracy(prediction,labels):\r\n",
        "    return sum(prediction==labels)/len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HD1jUsZAQMSf",
        "outputId": "b02e2981-9e84-48e4-d633-07c539cce568"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_checkpoints</th>\n",
              "      <th>result_method</th>\n",
              "      <th>pooling_method</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>base_only</td>\n",
              "      <td>None</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>all</td>\n",
              "      <td>max</td>\n",
              "      <td>0.490385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>all</td>\n",
              "      <td>min</td>\n",
              "      <td>0.451923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>all</td>\n",
              "      <td>mean</td>\n",
              "      <td>0.475000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bert-base-cased</td>\n",
              "      <td>base_only</td>\n",
              "      <td>None</td>\n",
              "      <td>0.701923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>bert-base-cased</td>\n",
              "      <td>all</td>\n",
              "      <td>max</td>\n",
              "      <td>0.526923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>bert-base-cased</td>\n",
              "      <td>all</td>\n",
              "      <td>min</td>\n",
              "      <td>0.549038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>bert-base-cased</td>\n",
              "      <td>all</td>\n",
              "      <td>mean</td>\n",
              "      <td>0.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>bert-large-uncased</td>\n",
              "      <td>base_only</td>\n",
              "      <td>None</td>\n",
              "      <td>0.788462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bert-large-uncased</td>\n",
              "      <td>all</td>\n",
              "      <td>max</td>\n",
              "      <td>0.539423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>bert-large-uncased</td>\n",
              "      <td>all</td>\n",
              "      <td>min</td>\n",
              "      <td>0.520192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>bert-large-uncased</td>\n",
              "      <td>all</td>\n",
              "      <td>mean</td>\n",
              "      <td>0.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>bert-large-cased</td>\n",
              "      <td>base_only</td>\n",
              "      <td>None</td>\n",
              "      <td>0.762500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>bert-large-cased</td>\n",
              "      <td>all</td>\n",
              "      <td>max</td>\n",
              "      <td>0.560577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>bert-large-cased</td>\n",
              "      <td>all</td>\n",
              "      <td>min</td>\n",
              "      <td>0.577885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>bert-large-cased</td>\n",
              "      <td>all</td>\n",
              "      <td>mean</td>\n",
              "      <td>0.588462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>roberta-base</td>\n",
              "      <td>base_only</td>\n",
              "      <td>None</td>\n",
              "      <td>0.713462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>roberta-base</td>\n",
              "      <td>all</td>\n",
              "      <td>max</td>\n",
              "      <td>0.547115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>roberta-base</td>\n",
              "      <td>all</td>\n",
              "      <td>min</td>\n",
              "      <td>0.564423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>roberta-base</td>\n",
              "      <td>all</td>\n",
              "      <td>mean</td>\n",
              "      <td>0.563462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>roberta-large</td>\n",
              "      <td>base_only</td>\n",
              "      <td>None</td>\n",
              "      <td>0.767308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>roberta-large</td>\n",
              "      <td>all</td>\n",
              "      <td>max</td>\n",
              "      <td>0.552885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>roberta-large</td>\n",
              "      <td>all</td>\n",
              "      <td>min</td>\n",
              "      <td>0.554808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>roberta-large</td>\n",
              "      <td>all</td>\n",
              "      <td>mean</td>\n",
              "      <td>0.575962</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model_checkpoints result_method pooling_method  accuracy\n",
              "0    bert-base-uncased     base_only           None  0.750000\n",
              "1    bert-base-uncased           all            max  0.490385\n",
              "2    bert-base-uncased           all            min  0.451923\n",
              "3    bert-base-uncased           all           mean  0.475000\n",
              "4      bert-base-cased     base_only           None  0.701923\n",
              "5      bert-base-cased           all            max  0.526923\n",
              "6      bert-base-cased           all            min  0.549038\n",
              "7      bert-base-cased           all           mean  0.550000\n",
              "8   bert-large-uncased     base_only           None  0.788462\n",
              "9   bert-large-uncased           all            max  0.539423\n",
              "10  bert-large-uncased           all            min  0.520192\n",
              "11  bert-large-uncased           all           mean  0.550000\n",
              "12    bert-large-cased     base_only           None  0.762500\n",
              "13    bert-large-cased           all            max  0.560577\n",
              "14    bert-large-cased           all            min  0.577885\n",
              "15    bert-large-cased           all           mean  0.588462\n",
              "16        roberta-base     base_only           None  0.713462\n",
              "17        roberta-base           all            max  0.547115\n",
              "18        roberta-base           all            min  0.564423\n",
              "19        roberta-base           all           mean  0.563462\n",
              "20       roberta-large     base_only           None  0.767308\n",
              "21       roberta-large           all            max  0.552885\n",
              "22       roberta-large           all            min  0.554808\n",
              "23       roberta-large           all           mean  0.575962"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "params={\n",
        "    'model_checkpoints':['bert-base-uncased','bert-base-cased','bert-large-uncased','bert-large-cased','roberta-base','roberta-large'],\n",
        "    'result_method':['base_only','all'],\n",
        "    'pooling_method':['max','min','mean']\n",
        "}\n",
        "\n",
        "col_names=['model_checkpoints','result_method','pooling_method','accuracy']\n",
        "\n",
        "result=[]\n",
        "for model_checkpoint in params['model_checkpoints']:\n",
        "    pretrained_model=pretrained_model_tester(test_data,model_checkpoint)\n",
        "    for result_method in params['result_method']:\n",
        "        if result_method=='base_only':\n",
        "            predictions=pretrained_model.batch_predict(result_method,None)\n",
        "            result.append([model_checkpoint,result_method,None,get_accuracy(predictions,test_answer)])\n",
        "        else:\n",
        "            for pooling_method in params['pooling_method']:\n",
        "                predictions=pretrained_model.batch_predict(result_method,pooling_method)\n",
        "                result.append([model_checkpoint,result_method,pooling_method,get_accuracy(predictions,test_answer)])\n",
        "\n",
        "result=pd.DataFrame(result,columns=col_names)\n",
        "display(result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "mid-term assignment",
      "provenance": []
    },
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3.6.7 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "metadata": {
      "interpreter": {
        "hash": "496b04e30059469958467f0d4db1620d644ed6cb7bd63306bef423de4168438b"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d48071e713443deb36c0f595aa836ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "Sentences 105 of 2977:   4%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ef09cf449c04a61a69624ca243565a1",
            "max": 417,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af51f64058e247eba64bd5ae998e765c",
            "value": 17
          }
        },
        "1c4387ee1a664793a3ef1beb09d8bcfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d48071e713443deb36c0f595aa836ad",
              "IPY_MODEL_8b665f90863f4c37a98d420ae64418e2"
            ],
            "layout": "IPY_MODEL_1d57ab7be64d4291b9149a0676d8f2c8"
          }
        },
        "1d57ab7be64d4291b9149a0676d8f2c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33bfd4c2e22f41d490f38fdbe7328e51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef09cf449c04a61a69624ca243565a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b665f90863f4c37a98d420ae64418e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33bfd4c2e22f41d490f38fdbe7328e51",
            "placeholder": "â",
            "style": "IPY_MODEL_b9eb33d0c74b4b89959c78a3c99f0905",
            "value": " 17/417 [3:01:12&lt;41:50:55, 376.64s/it]"
          }
        },
        "af51f64058e247eba64bd5ae998e765c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "b9eb33d0c74b4b89959c78a3c99f0905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}